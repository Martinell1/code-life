> 从输入 URL 到页面加载完成，发生了什么？

1. 首先我们需要通过 DNS（域名解析系统）将 URL 解析为对应的 IP 地址

2. 然后与这个 IP 地址确定的那台服务器建立起 TCP 网络连接

3. 随后我们向服务端抛出我们的 HTTP 请求

4. 服务端处理完我们的请求之后，把目标数据放在 HTTP 响应里返回给客户端，拿到响应数据的浏览器就可以开始走一个渲染的流程

5. 渲染完毕，页面便呈现给了用户，并时刻等待响应用户的操作

   

1. DNS 解析
2. TCP 连接
3. HTTP 请求抛出
4. 服务端处理请求，HTTP 响应返回
5. 浏览器拿到响应数据，解析响应内容，把解析的结果展示给用户



HTTP优化方向

- 减少请求次数

- 减少单次请求所花费的时间



webpack的优化瓶颈

- webpack 的构建过程太花时间

- webpack 打包的结果体积太大

  

## webpack的优化方案

不要让 loader 做太多事情——以 babel-loader 为例

babel-loader 无疑是强大的，但它也是慢的。

最常见的优化方式是，用 include 或 exclude 来帮我们避免不必要的转译，比如 webpack 官方在介绍 babel-loader 时给出的示例：

```js
module: {
  rules: [
    {
      test: /\.js$/,
      exclude: /(node_modules|bower_components)/,
      use: {
        loader: 'babel-loader',
        options: {
          presets: ['@babel/preset-env']
        }
      }
    }
  ]
}
```

这段代码帮我们规避了对庞大的 node_modules 文件夹或者 bower_components 文件夹的处理。但通过限定文件范围带来的性能提升是有限的。除此之外，如果我们选择开启缓存将转译结果缓存至文件系统，则至少可以将 babel-loader 的工作效率提升两倍。要做到这点，我们只需要为 loader 增加相应的参数设定:

```js
loader: 'babel-loader?cacheDirectory=true'
```

以上都是在讨论针对 loader 的配置，但我们的优化范围不止是 loader 们。

举个🌰，尽管我们可以在 loader 配置时通过写入 exclude 去避免 babel-loader 对不必要的文件的处理，但是考虑到这个规则仅作用于这个 loader，像一些类似 UglifyJsPlugin 的 webpack 插件在工作时依然会被这些庞大的第三方库拖累，webpack 构建速度依然会因此大打折扣。所以针对这些庞大的第三方库，我们还需要做一些额外的努力。